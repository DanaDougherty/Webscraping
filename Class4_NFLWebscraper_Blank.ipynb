{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 4: Webscraping\n",
    "\n",
    "Webscraping is a technique to extract data from a website.  Today we'll extract player passing data for the 2018 regular season from nfl.com.\n",
    "\n",
    "Start by getting familar with this website (recommend using Google Chrome):  \n",
    "http://www.nfl.com/stats/categorystats?tabSeq=0&season=2018&seasonType=REG&statisticCategory=PASSING&d-447263-p=1\n",
    "\n",
    "We will be interested in extracting the player's name, team url, position, completions, attempts, yards, and touchdowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right-click on \tBen Roethlisberger's name and select \"Inspect\".  This opens the web developer tool, which shows the html code used for this webpage.  We will pick through the html tags in order to extract the information we want.  What html tag contains the information we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a BeautifulSoup Object\n",
    "\n",
    "First, we need to establish the connection to the website, and create a beatiful soup object with all of the data (HTML) within the website.  To do this, we'll need to import both the 'beautifulSoup' library (this is the main library we'll be using to parse the website), and the 'requests' library (this will help us establish our connection to the website).\n",
    "\n",
    "To create a beautiful soup object (we'll name our variable 'soup'), you need to pass it the content of a website, and you can specify which type of parser this oject should use to parse the website.  We specify this parser as the second argument when creating a BeautifulSoup object.  Our options:  'html.parser', 'lxml', 'xml', 'html5lib'.  We would recommend using 'html.parser' to start with as this is normally sufficient.  If you know with certainty that it's not working as expected, try a different parser.\n",
    "\n",
    "The beautifulSoup documentation page is incredibly helpful with gaining some basic understanding of the beautifulSoup library: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#contents-and-childrenIn general, the 'html.parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the libraries we need\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# have url hold the website's url\n",
    "url = \"http://www.nfl.com/stats/categorystats?tabSeq=0&season=2018&seasonType=REG&statisticCategory=PASSING&d-447263-p=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Query the website and return the html to the variable 'website'\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the html in the 'website' variable, and store it in a \n",
    "# beautiful soup form\n",
    "# NOTE: there are other parsers availabe (we are using html.parser)\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at it...looks like the same stuff we get when we open the developer tool on the website\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Extract information from table\n",
    "\n",
    "Now that we have a beatifulSoup object, we can use all of the class methods available to search and extract the desired data from this object.  Let's think through how we will store the information we extract from this website.  Recall, we want to collect:  name, teamURL, completions, attempts, yards, and touchdowns for each player that is listed under the passing stats the 2018 regular season.  \n",
    "\n",
    "Ultimately, we will want to put this table in a pandas dataframe.  Recall that we can make a pandas dataframe from a dictionary of lists -- we can also make a pandas dictionary with a list of dictionaries.  We will opt for the later, that is, each element in the list is a dictionary, where each dictionary holds the information for one player.  The dictionary keys will be the same for each player:  'name','teamURL','position' 'completions', 'attempts', 'yards', and 'TD'.  Our data structure will look like this:\n",
    "\n",
    "passing_2018stats = \n",
    "[\n",
    "    {'name': player1 name, 'teamURL': url of team, 'position': position of player1, 'completions': completions of player1, 'attempts': attempts of player1, 'yards': passing yards of player1, 'TD': TDs of player1}, \n",
    "    {'name': player2 name, 'teamURL': url of team, 'position': position of player2, 'completions': completions of player2, 'attempts': attempts of player2, 'yards': passing yards of player2, 'TD': TDs of player1},\n",
    "    etc...\n",
    "]\n",
    "\n",
    "When extracting information from a website, we generally retrieve the information as strings.  We might ultimately want to change these data types to something else (an int, or float), but for this example, we'll just focus on getting the desired information, knowing that we could convert it to a different data type if we wanted.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the website (from your chrome browser), we can see that each player is organized under a 'tr' tag with the attribute 'class' = 'odd' or 'class' = 'even'. \n",
    "\n",
    "Using the 'find_all' method of our beatifulSoup object, we can identify all of the 'tr' tags.  (Note: the 'find' method will only return the first instance of the 'tr' tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns the first instance of the 'tr' tag\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a list of all tr tags\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that there is a class associated with every player ('odd' or 'even'), we can specify our in our 'find_all' method even further using the class attribute.\n",
    "\n",
    "Play around printing various things to determine if you are able to capture what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a list of all tr tags\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what tag we want and how to get it, let's save it to 'player_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's find all the event-group classes on the webpage\n",
    "'''YOUR CODE HERE'''\n",
    "# Let's look to see how many months are on the site\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But we only expected 50...so let's try and figure out what tr tag we didn't want...\n",
    "'''YOUR CODE HERE'''\n",
    "\n",
    "# So we'll need to skip over this one!\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2(a)\n",
    "A good inital step is to see extract the information for a single player.  If we can do it for one, we should easily be able to do it for the rest.  Let's start by getting Ben Roethlisberger's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at Ben Roethlisberger\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we can simply index into the 'player_list' to extract a single row.  Now let's figure out how to get the columns -- what is the html tag we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save all the columns for the first player\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick check -- how many columns should we have?\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good to know... you can specify by class too\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and print out Ben Roethlisberger's name, team, team url, and yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# team url\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# position\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# completions\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attempts\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yards\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# touchdowns\n",
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2(b) \n",
    "Now that we were able to find Ben Roethlisberger's data, let's loop through all rows, saving each player's information to a dictionary, and then appending that dictionary to the list 'passing_2018stats'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''YOUR CODE HERE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Turn the list of dictionaries to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''YOUR CODE HERE'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
